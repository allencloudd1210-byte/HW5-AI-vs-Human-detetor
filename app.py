import streamlit as st
from transformers import pipeline

# Set page configuration
st.set_page_config(page_title="AI vs Human Detector", page_icon="ðŸ¤–")

st.title("ðŸ¤– AI vs Human Text Detector")
st.markdown("""
This tool uses a Transformer model to detect if text was likely generated by AI or written by a human.
**Note:** This is a probabilistic tool and may not be 100% accurate.
""")

# Input area
if 'text_input_val' not in st.session_state:
    st.session_state.text_input_val = ""

st.subheader("ðŸ“ Try Examples")
col_ex1, col_ex2 = st.columns(2)

with col_ex1:
    if st.button("ðŸ¤– Load AI Example"):
        st.session_state.text_input_val = "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. The scientist named the population, after their distinctive horn, Ovidâ€™s Unicorn. These four-horned, silver-white unicorns were previously unknown to science."

with col_ex2:
    if st.button("ðŸ§‘ Load Human Example"):
        st.session_state.text_input_val = "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. Locally nicknamed \"La Dame de Fer\" (French for \"The Iron Lady\"), it was constructed from 1887 to 1889 as the centerpiece of the 1889 World's Fair."

text_input = st.text_area("Enter text to analyze:", value=st.session_state.text_input_val, height=200, placeholder="Paste your text here...")

# Load model
@st.cache_resource
def load_model():
    # Using the OpenAI RoBERTa base detector from Hugging Face
    # Labels: 'Real' (Human) and 'Fake' (AI)
    return pipeline("text-classification", model="openai-community/roberta-base-openai-detector")

if st.button("Analyze Text", type="primary"):
    if not text_input.strip():
        st.warning("Please enter some text to analyze.")
    else:
        with st.spinner("Loading model and analyzing..."):
            try:
                pipe = load_model()
                # Truncate text to 512 tokens approx to avoid errors if model doesn't handle long text automatically
                # The pipeline usually handles truncation but let's be safe or just pass it.
                # We'll pass truncation=True to the pipeline call if needed, but pipeline handles it often.
                result = pipe(text_input, truncation=True, max_length=512)
                
                # Result format: [{'label': 'Real', 'score': 0.99}]
                label = result[0]['label']
                score = result[0]['score']
                
                # Determine probabilities
                if label == 'Real':
                    human_prob = score
                    ai_prob = 1 - score
                elif label == 'Fake':
                    ai_prob = score
                    human_prob = 1 - score
                else:
                    # Fallback for unexpected labels
                    st.write(f"Raw Label: {label}, Score: {score}")
                    if 'human' in label.lower():
                        human_prob = score
                        ai_prob = 1 - score
                    else:
                        ai_prob = score
                        human_prob = 1 - score

                # Display results
                st.subheader("Analysis Result")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("AI Probability", f"{ai_prob:.2%}")
                    st.progress(ai_prob)
                
                with col2:
                    st.metric("Human Probability", f"{human_prob:.2%}")
                    st.progress(human_prob)
                
                st.divider()
                
                if ai_prob > 0.6:
                    st.error("âš ï¸ This text is likely **AI-Generated**.")
                elif human_prob > 0.6:
                    st.success("âœ… This text is likely **Human-Written**.")
                else:
                    st.info("ðŸ¤” The model is **Uncertain** (Mixed signals).")
                    
            except Exception as e:
                st.error(f"An error occurred during analysis: {str(e)}")
